# 【学习笔记】 Kafka 权威指南

> 版权声明：欢迎各位转载，但是未经作者本人同意，转载文章之后必须在文章页面明显位置给出作者和原文连接，否则保留追究法律责任的权利。 {{site.url}}{{page.url}}

## 初识 Kafka

### Kafka 简介

Kafka 是一款基于发布与订阅的消息系统，一般被称为“分布式提交日志”或者“分布式流平台”。Kafka 的数据是按照一定顺序持久化保存的，可以按需读取。此外， Kafka 的数据分布在整个系统里，具备数据故障保护和性能伸缩能力。

- 消息：Kafka 的数据单元
    - 可视为数据库里的一个“数据行”或一条“记录”。
    - 由字节数组组成，即消息里的数据没有特别的格式或含义。
    - 消息有一个可选的元数据（Meta Data），也就是键。键同样也是字节数组，无特别的含义。当消息以一种可控的方式写入不同的分区时，会用到键。
    - 为了提高效率，消息会被分批次写入 Kafka。批次，即一组属于同一个主题和分区的消息。批次需要在时间延迟和吞吐量之间进行权衡。
        - 批次越大，单位时间处理的消息就越多，单次传输时间就越长。
        - 批次数据会被压缩，这样可以提高数据传输和存储能力，但需要更多的计算。
- 模式：消息内容的结构
    - 由于消息是无特别含义的字节数组，所以需要额外的结构来定义消息内容。
    - 可用选项：JSON，XML，Apache Avro（偏好）
- 主题和分区：消息的分类单元
    - 主题类似于数据库的表，主题可被分为多个分区。
    - 分区就是一个提交日志，消息以追加的方式写入分区，然后以先入先出的顺序读取。
    - 主题的消息顺序无法保证，但分区的顺序可以保证。
    - Kafka  通过分区实现数据冗余和伸缩性。分区可以分布在不同服务器上。
    - 人们通常用流描述 Kafka 这类系统的数据。很多时候，一个主题的数据被看做是一个流，不管它有多少分区。流式一组从生产者移动到消费者的数据。
- 生产者和消费者：Kafka 系统的用户
    - Kafka 的客户端就是 Kafka 系统的用户，它们被分为两种类型：生产者和消费者。
    - 生产者创建消息。
    - 消费者读取消息。消费者订阅一个或多个主题，按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。
        - 偏移量是一种元数据，是一个不断递增的整数值，在创建消息时，Kafka 会将其添加到消息里。
        - 在给定的分区里，每个消息的偏移量都是唯一的。
        - 消费者把每个分区最后读取的消息偏移量保存在 ZooKeeper 或 Kafka 上，即使消费者关闭或重启，它的读取状态不会消失。
    - 消费者是消费者群组的一部分，即会有多个消费者共同读取同一主题。群组保证每个分区智能被一个消费者使用。消费者与分区之间的映射被称为消费者对分区的所有权关系。
- broker 和集群
    - broker：一个独立的 Kafka 服务器。
        - 接受来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保持。
        - 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。
    - 集群：一组 broker
        - 每个集群都有一个 broker 同时充当集群控制器的角色，负责管理工作，包括将分区分配给 broker 和监控 broker。
        - 在集群中，一个分区从属于一个 broker，该 broker 被称为分区的首领。一个分区可被分配给多个 broker，此时会发生分区复制，该机制可为分区提供消息冗余，若有一个 broker 失效，其他 broker 可接管领导权。
    - 保留消息（在一定期限内）是 Kafka 的一个重要特性。
        - broker 的默认消息保留策略：
            - 要么保留一段时间，比如 7 天。
            - 要么保留消息达到一定大小的字节数，比如 1 GB。
    - 多集群
        - 基于以下几个情况，可考虑使用多集群
            - 数据类型分离
            - 安全需求隔离
            - 多数据中心（灾难恢复）：需要注意，Kafka 的消息复制机制只能在单个集群里进行。但 Kafka 提供了一个 MirrorMaker 的工具，可实现集群间的消息复制。
            
### 为什么要用 Kafka

- 多生产者无缝支持，无需额外的协调管理。
- 多消费者的数据读取互不影响。
- 数据持久化，允许消费者非实时读取数据。
- 伸缩性，可随时对在线集群进行扩展。
- 高性能，能在处理大量数据的同时，保证亚秒的消息延迟。
- 数据生态系统支持

### 使用场景

- 用户活动跟踪
- 传递消息
- 度量指标和日志记录
- 提交日志
- 流处理

## Kafka 安装与配置

### 安装

1. 前置安装
    - JAVA
    - Zookeeper：Kafka 使用 Zookeeper 保存集群的元数据信息和消费者信息。Kafka 发行版自带 Zookeeper，可直接从脚本启动。
    - Kafka：[下载地址](http://kafka.apache.org/downloads.html)

2. 安装成功测试
    - 启动 Zookeeper：`zookeeper-server-start.bat ..\..\config\zookeeper.properties`
    - 启动 Kafka：`kafka-server-start.bat ..\..\config\server.properties`
    - 创建主题：`kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kafka-test-topic`
    - 验证主题：`kafka-topics.bat --zookeeper localhost:2181 --describe --topic kafka-test-topic`
    - 启动生产者发送消息：`kafka-console-producer.bat --broker-list localhost:9092 --topic kafka-test-topic`
    - 启动消费者接受消息：`kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic kafka-test-topic --from-beginning`
    
### 配置

1. broker 配置
    - broker.id：默认值为0，在整个 Kafka 集群里必须是唯一值。
    - port：默认值为 9092。使用 1024 以下的端口需要 root 权限启动 Kafka。
    - zookeeper.connect：指定保存 broker 元数据的 Zookeeper 地址，配置格式：`hostname:port/path`
        - hostname：Zookeeper 服务器的机器名或 IP。
        - port：Zookeeper 的端口。
        - /path：可选， Zookeeper 路径，作为 Kafka 集群的 chroot 环境。若不指定，默认使用根路径。若指定路径不存在，broker 会在启动时创建它。
    - log.dirs：存放日志片段的目录，用逗号分隔。
    - num.recovery.threads.per.data.dir：默认情况下，每个日志记录只使用一个线程。
    - auto.create.topics.enable：默认情况下，Kafka 会在以下几种情况下自动创建主题：生产者写入消息，消费者读取消息，客户端向主题发送元数据请求。
2. 主题配置
    - num.partitions：分区数量，默认值为 1。
    - log.retention.ms：数据保留时间，默认值为 168 小时（1 周）。
    - log.retention.bytes：保留的最大消息字节数，作用于每个分区，默认值为 1 GB。
    - log.segment.bytes：日志片段的最大字节数，默认值为 1 GB。
    - log.segment.ms：日志片段的最长开启时间，无默认值。
    - message.max.bytes：单个消息的最大字节数，默认值为 1000000。
    
3. 硬件影响因素
    - 磁盘吞吐量
    - 磁盘容量
    - 内存
    - 网络
    - CPU

4. 集群配置
    - broker 数量
    - broker 配置
    - 操作系统调优
        - 虚拟内存
        - 磁盘
        - 网络
        
5. 生产环境
    - 垃圾回收器选项
    - 数据中心布局
    - 共享 Zookeeper
    
## Kafka 生产者——向 Kafka 写入数据

[官方使用指南](https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md)

### 创建 生产者

```c++
std::string brokers = "localhost";
std::string errstr;
std::string topic_name = "test";
int32_t partition = RdKafka::Topic::PARTITION_UA;
// 创建 Producer 配置 和 Topic 配置
std::unique_ptr<RdKafka::Conf> conf(RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL));
std::unique_ptr<RdKafka::Conf> tconf(RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC));
conf->set("bootstrap.servers", brokers, errstr);

// 创建 Producer 对象 和 Topic 对象
std::unique_ptr<RdKafka::Producer> producer(RdKafka::Producer::create(conf.get(), errstr));
if (!producer)
{
	std::cerr << "Failed to create producer" << errstr << std::endl;
}
std::cout << "Created Producer : " << producer->name() << std::endl;
std::unique_ptr<RdKafka::Topic> topic(RdKafka::Topic::create(producer.get(), topic_name, tconf.get(), errstr));
if (!topic)
{
	std::cerr << "Failed to create topic" << errstr << std::endl;
}
```



### 发送消息

```c++
// 循环从标准输入读取消息内容
for (std::string line; run && std::getline(std::cin, line);)
{
	if (line.empty())
	{
		producer->poll(0);
		continue;
	}
	// 生产消息
	RdKafka::ErrorCode resp = producer->produce(topic.get(), partition, 
		RdKafka::Producer::MSG_COPY, 
		const_cast<char *>(line.c_str()), 
		line.size(), 
		NULL, 
		NULL);
	if (resp != RdKafka::ERR_NO_ERROR)
	{
		std::cerr << "Produce failed" << RdKafka::err2str(resp) << std::endl;
	}else
	{
		std::cout << "Produce message " << line.size() << " bytes " << std::endl;
	}

	producer->poll(0);
}

// 退出前处理完输出队列中的消息
while (run && producer->outq_len() > 0)
{
	std::cerr << "Waiting for " << producer->outq_len() << std::endl;
	producer->poll(1000);
}
RdKafka::wait_destroyed(5000);
```
- `rd_kafka_produce()` is a non-blocking API, it will enqueue the message on an internal queue and return immediately. If the number of queued messages would exceed the `queue.buffering.max.messages` configuration property then `rd_kafka_produce()` returns `-1` and sets errno to `ENOBUFS` and last_error to `RD_KAFKA_RESP_ERR__QUEUE_FULL`, thus providing a backpressure mechanism.

### 重要配置参数（[Configuration properties](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)）
- `acks`：指定必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。该参数对消息丢失的可能性有重要影响。
    - 若 acks=0，生产者不会等待任何来自服务器的确认响应，可以以最大速度发送消息，从而达到很高吞吐量。
- `buffer.memory`：设置生产者内存缓冲区大小，用于缓冲要发送到服务器的消息。（目前已被替换为 queue.buffering.max.kbytes 等参数配置）
- `compression.type`：消息压缩算法类型。
    - 默认情况下，不进行压缩。
    - snappy 压缩算法由 Google 发明，CPU 占用少，性能和压缩比皆可观，若比较关注性能和网络带宽，可使用该算法。
    - gzip 压缩算法 CPU 占用更多，而压缩比更高，若带宽有限，可用该算法。
- `retries`：决定生产者重发消息次数，因生产者从服务器收到的错误有可能是临时性错误。
    - 默认情况下，重试间隔时间为 100 ms，可通过 `retry.backoff.ms` 参数来改变。
- `batch.size`：指定一个批次消息可用的内存大小，按字节数计算。
    - 当批次被填满，批次里所有消息会被发送出去。
    - 生产者并不一定等批次填满才发送，还与 linger.ms 有关。
- `linger.ms`：指定生产者在发送批次之前等待更多消息加入批次的时间。生产者会在批次填满或 linger.ms 达到上限时把批次发送出去。
    - 默认情况下，只要有可用线程，生产者就会把消息发送出去，即使批次里只有一个消息。
- `client.id`：用于识别消息来源。
- `max.in.flight.requests.per.connection`：指定生产者在收到服务器响应之前可发送多少消息。
- `timeout.ms`：broker 等待同步副本返回消息确认的时间。
- `request.timeout.ms`：生产者在发送数据时等待服务器返回响应的时间。
- `metadata.fetch.timeout.ms`：生产者在获取元数据时等待服务器返回响应的时间。
- `receive.buffer.bytres` 和 `send.buffer.bytes`：TCP socket 接收/发送数据包的缓冲大小。若为0，就使用操作系统的默认值。若生产者或消费者与broker 处于不同的数据中心，则可适当增大这些值。

## Kafka 消费者——从 Kafka 读取数据

### 创建 消费者
```c++
std::string brokers = "localhost";
std::string errstr;
std::string topic_name = "test";
int32_t partition = 0;
// 创建 Consumer 配置 和 Topic 配置
std::unique_ptr<RdKafka::Conf> conf(RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL));
std::unique_ptr<RdKafka::Conf> tconf(RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC));
conf->set("bootstrap.servers", brokers, errstr);

// 创建 Consumer 对象 和 Topic 对象
std::unique_ptr<RdKafka::Consumer> consumer(RdKafka::Consumer::create(conf.get(), errstr));
if (!consumer)
{
	std::cerr << "Failed to create consumer" << errstr << std::endl;
}
std::cout << "Created Consumer : " << consumer->name() << std::endl;
std::unique_ptr<RdKafka::Topic> topic(RdKafka::Topic::create(consumer.get(), topic_name, tconf.get(), errstr));
if (!topic)
{
	std::cerr << "Failed to create topic" << errstr << std::endl;
}
```

### 消费消息

```c++
RdKafka::ErrorCode resp = consumer->start(topic.get(), partition, start_offset);
if (resp != RdKafka::ERR_NO_ERROR)
{
	std::cerr << "Consumer start failed" << RdKafka::err2str(resp) << std::endl;
}

int i = 0;
while(i < 100)
{
	std::unique_ptr<RdKafka::Message> msg(consumer->consume(topic.get(), partition, 1000));
	msg_consume(msg.get(), nullptr);
	consumer->poll(0);
	++i;
}

consumer->stop(topic.get(), partition);
consumer->poll(1000);
```
`msg_consume`：消息验证
```c++
void msg_consume(RdKafka::Message* message, void* opaque) {
	switch (message->err()) {
	case RdKafka::ERR__TIMED_OUT:
		break;

	case RdKafka::ERR_NO_ERROR:
		/* Real message */
		std::cout << "Read msg at offset " << message->offset() << std::endl;
		if (message->key()) {
			std::cout << "Key: " << *message->key() << std::endl;
		}
		printf("%.*s\n",
			static_cast<int>(message->len()),
			static_cast<const char *>(message->payload()));
		break;

	case RdKafka::ERR__PARTITION_EOF:
		/* Last message */
		if (exit_eof) {
			run = false;
		}
		break;

	case RdKafka::ERR__UNKNOWN_TOPIC:
	case RdKafka::ERR__UNKNOWN_PARTITION:
		std::cerr << "Consume failed: " << message->errstr() << std::endl;
		run = false;
		break;

	default:
		/* Errors */
		std::cerr << "Consume failed: " << message->errstr() << std::endl;
		run = false;
	}
}
```

- 轮询 `poll()` ：轮询不只是获取数据
    - 第一次调用新消费者的 poll() 方法时，它会负责查找 GroupCoordinator，然后加入群组，接受分配的分区。
    - 若发生了再均衡，整个过程也是轮询期间发生的。
    - 心跳也是轮询期间发送的。
    
### 重要的配置参数（[Configuration properties](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)）
- `group.id`：指定消费者属于哪一个消费者群组。
- `fetch.min.bytes`：消费者从服务器获取记录的最小字节数。它会等到有足够的可用数据时才返回给消费者，即可降低消费者和 broker 的工作负载。
- `fetch.max.wait.ms`：指定 broker 的等待时间，若fetch.min.bytes 未得到满足也强制返回给消费者。默认值为 500 ms。与 fetch.min.bytes 配合使用。
- `max.partition.fetch.bytes`：服务器从每个分区里返回给消费者的最大字节数，默认值为 1 MB。
- `session.timeout.ms`：消费者在死亡之前可以与服务器断开连接的时间，默认是 3 s。
    - 若在指定时间内消费者未发送心跳给群组协调器，则被认为死亡，协调器会触发再均衡，把它的分区分配给群组里的其他消费者。
    - 该属性与 heartbeat.interval.ms 紧密相关。
- `auto.offset.reset`：消费者在读取一个没有偏移量的分区或者偏移量无效的情况下，该作何处理。
    - latest（默认值），即从最新的记录开始读取数据。
    - earliest，从起始位置开始读取分区。
- `enable.auto.commit`：消费者是否自动提交偏移量，默认值是 true。auto.commit.interval.ms 控制提交频率。
- `partition.assignment.strategy`：分区分配策略
    - Range：把主题的若干连续分区分配给消费者。
    - RoundRobin：将分区逐个分配给消费者。
- `max.poll.records`：单次调用 poll() 方法能够返回的记录数量，用于控制轮询里需要处理的数据量。
- `client.id`：broker
    
### 提交和偏移量
- 每次调用 poll() 方法，它总是返回由生产者写入 Kafka 但还没被消费者读取过的记录，因此可追踪到哪些记录是被群组里的哪个消费者读取的。
- 偏移量：消息在分区中的位置
- 提交：更新分区当前位置的操作
- 提交偏移量：消费者往一个名为 `__consumer_offset` 的特殊主题发送消息，消息里包含每个分区的偏移量。 
    - 当消费者发生崩溃或者有新的消费者加入群组，则触发再均衡，即每个消费者可能分配到新的分区。为了继续工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方处理。
    - 若提交的偏移量小于客户端处理的最后一个消息的偏移量，则两个偏移量之间的消息会被重复处理。
    - 若提交的偏移量大于客户端处理的最后一个消息的偏移量，则两个偏移量之间的消息会丢失。
- 偏移量提交方式
    - 自动提交：`enable.auto.commit = true`
        - 每过 `auto.commit.intervals.ms`（默认值为 5s），消费者会自动把从 poll() 方法接收到的最大偏移量提交上去。
        - 自动提交发生在 poll() 轮询期间，即轮询时会检查是否该提交，若是，则提交从上一次轮询返回的偏移量。
    - 手动提交：`enable.auto.commit = false`
        - `commitSync()`（同步提交）：提交由 poll() 返回的最新偏移量。只要没发生不可恢复的错误，`commitSync()`会一直尝试直至提交成功。
        - `commitAsync()`（异步提交）：提交偏移量，无需等待 broker 响应。
        - 同步异步组合提交：主要使用异步提交，但在 finally 部分使用同步，即关闭消费者时使用同步确保提交。
    - 提交特定偏移量：半个批次消息提交。
        - 消费者 API 允许在调用 commitSync() 和 commitAsync() 时传进去希望提交的分区和偏移量。
        
- 从特定偏移量处开始处理记录：`seek()`

### 安全退出轮询
- `consumer.wakeup()`
    - 在另一个线程调用该方法。
    - 该方法会抛出 WakeUpException 异常，该异常用于跳出轮询循环，无需处理。
    - 退出轮询线程前，调用 `consumer.close()`。