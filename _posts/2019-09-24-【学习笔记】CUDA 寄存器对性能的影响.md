【学习笔记】CUDA 寄存器对性能的影响

> 版权声明：欢迎各位转载，但是未经作者本人同意，转载文章之后必须在文章页面明显位置给出作者和原文连接，否则保留追究法律责任的权利。 {{site.url}}{{page.url}}

## 寄存器介绍

> 引自 tiemaxiaosu 的 [CUDA学习（十） 寄存器用法](https://blog.csdn.net/tiemaxiaosu/article/details/52932455)

### 映射寄存器方式

CPU与GPU架构的一个主要区别就是CPU与GPU映射寄存器的方式。CPU通过使用寄存器重命名和栈来执行多线程。为了运行一个新的任务，CPU需要进行上下文切换，将当前所有寄存器的状态保存到栈（系统内存）上，然后从栈恢复当前需要执行的新线程上次的执行状态。这些操作通常需要花费上百个CPU时钟周期。如果在CPU上开启过多的线程，时间几乎都将花费在上下文切换过程中寄存器内容的切换进/换出操作上。因此，如果在CPU开启过多线程，有限工作的吞吐量将会快速降低。

然而，GPU却恰恰相反。GPU利用多线程隐藏了内存获取与指令执行带来的延迟。因此，在GPU上开启过少的线程反而会因为内存事务使GPU处于闲置状态。此外，GPU也不使用寄存器重命名的机制，而是致力于为每个线程分配真是寄存器。因此，当需要上下文切换时，所需要的操作就是将指向当前寄存器的选择器（或指针）更新，以指向下一个执行的线程束的寄存器，因此几乎零开销。

### 寄存器空间大小

由于所使用的硬件不同，每个SM可供所有线程使用的寄存器空间大小也不同，分布有8KB、16KB、32KB、64KB。牢记，每个线程中每个变量会占用一个寄存器。因此，C语言中的一个浮点型变量就会占用N个寄存器，其中N代表调度的线程数量。在费米架构的设备上，每个SM拥有32KB 的寄存器空间。如果每个线程块有256个线程，则每个线程可以使用32（32768/4/256）个寄存器。为了让费米架构的设备上的每个线程可以使用的寄存器数目达到最大，即64 个寄存器（G80及GT200上最多128个），每个线程块上的线程数目需要减少一半，即128。当线程块上的寄存器数目是允许的最大值时，每个SM会只处理一个线程块。同样，也可以使用四个线程块，每个线程块32个线程（4*32=128个线程），每个线程使用的寄存器数目也能达到最多。

### SM调度线程块数目

大多数内核对寄存器的需求量都很低。如果将寄存器的需求量从128降到64，则相同的SM上可再调度一个线程块。例如需要32个寄存器，则可调度4个线程块。通过这样做，运行的线程总数可以提高。在费米型设备上，每个SM最多能运行1536个线程。一般情况下，占用率越高，程序运行就越快。

但是，每个SM能够调度的线程束的数量也是有限的。因此，将每个线程需要的寄存器数量从32降到16，并不意味着SM能调度8个线程块。如下表：

- 线程数为 192

|最多使用寄存器数目|16|20|24|28|32|64|
|--|--|--|--|--|--|--|
|线程块调度数|8|8|7|6|5|2|

- 线程数为 256

|最多使用寄存器数目|16|20|24|28|32|64|
|--|--|--|--|--|--|--|
|线程块调度数|6|6|5|4|4|2|

表中测试设备为费米架构的设备。至于开普勒架构的设备，只需简单的将表中的寄存器数目与线程块数目加倍即可。此处使用192和256个线程进行测试是因为他们能够保证硬件的充分利用。注意当内核使用的寄存器的数目为16与20时，SM上调度的线程块的数目并没有增加，这是因为分配到每个SM上的线程的数量是有限的。在这种情况下，可以不考虑是否影响每个SM运行的线程总数而直接增加寄存器的使用量。

### 寄存器运用

将结果累积在寄存器中可省去大量的内存写操作。这种寄存器的优化方式可以使程序执行速度得到很大的提高。然而，这种优化方式需要程序员思考哪些参数是存于寄存器中，哪些参数是存于内存中，哪些参数需要从寄存器中复制回内存，等等。基于寄存器的优化能够为代码的执行时间带来巨大影响。使用寄存器可以有效消除内存访问，或提供额外的ILP，以此实现GPU内核函数的加速，这是最为有效的方法之一。

## 寄存器相关的性能问题

### 案例一

```c++
#define LENGTH 64

__device__ __forceinline__ void CalcResults1(int* results, int* a, int* b, int length){
    for (int i = 0; i < length; ++i){
        results[i] = a[i] * b[i];
    }
}

__device__ __forceinline__ void CalcResults2(int* results, int* a, int* b, int length){
    int temp_results[LENGTH] { 0 };

    for (int i = 0; i < length; ++i){
        temp_results[i] = a[i] * b[i];
    }

    for (int i = 0; i < length; ++i){
        results[i] = temp_results[i];
    }
}
__global__ void foo(int* a, int* b, int* c){
    int results[LENGTH] { 0 };
    int length = LENGTH;

    CalcResults1(results, a, b, length);
    CalcResults2(results, a, b, length);
}

```

- 现象：在上述代码中，虽然 `CalcResults2` 比 `CalcResults1` 的代码要复杂，但实际上 `CalcResults2` 比 `CalcResults1` 要更快。
- 原因：通过 [cuobjdump](https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html#cuobjdump) 导出 CUDA 的汇编源码可知，因为 `CalcResults2` 通过声明定义 `temp_results` 局部数组变量强制申请了更多的寄存器，使得在运算过程中能有更多的寄存器来使用，从而减少一些汇编指令的使用。
- 结论：当核函数未充分使用计算资源时，通过一些手段增加核函数内寄存器的使用，可在一定程度上提升性能。

### 案例二

- 现象：CUDA 可能优化局部变量数组，使其尽可能少使用寄存器
    - 当发现多个局部变量被赋值同一个值时，为了减少寄存器的使用，编译器可能会只使用一个寄存器来表示这组局部变量的共同值。
- 原因：编译器会根据代码进行优化，尽可能少使用寄存器。
- 解决方案：给局部变量初始化赋值易促使局部变量被分配寄存器。
- 衍生现象：当单个线程循环往不同地址赋值时，从多个不同的寄存器取值比从同一个寄存器取值更快。

## 寄存器相关优化方案

### Launch Bounds 优化
> 引自官方文档：[Launch Bounds](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#ixzz4kk6SRKqY)

As discussed in detail in Multiprocessor Level, the fewer registers a kernel uses, the more threads and thread blocks are likely to reside on a multiprocessor, which can improve performance.

Therefore, the compiler uses heuristics to minimize register usage while keeping register spilling (see Device Memory Accesses) and instruction count to a minimum. An application can optionally aid these heuristics by providing additional information to the compiler in the form of launch bounds that are specified using the __launch_bounds__() qualifier in the definition of a __global__ function:

```c++
__global__ void
__launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor)
MyKernel(...)
{
    ...
}
```
- `maxThreadsPerBlock` specifies the maximum number of threads per block with which the application will ever launch `MyKernel()`; it compiles to the `.maxntid` PTX directive;
- `minBlocksPerMultiprocessor` is optional and specifies the desired minimum number of resident blocks per multiprocessor; it compiles to the `.minnctapersm` PTX directive.

If launch bounds are specified, the compiler first derives from them the upper limit L on the number of registers the kernel should use to ensure that `minBlocksPerMultiprocessor` blocks (or a single block if `minBlocksPerMultiprocessor` is not specified) of `maxThreadsPerBlock` threads can reside on the multiprocessor (see Hardware Multithreading for the relationship between the number of registers used by a kernel and the number of registers allocated per block). The compiler then optimizes register usage in the following way:
- If the initial register usage is higher than L, the compiler reduces it further until it becomes less or equal to L, usually at the expense of more local memory usage and/or higher number of instructions;
- If the initial register usage is lower than L
    - If `maxThreadsPerBlock` is specified and `minBlocksPerMultiprocessor` is not, the compiler uses `maxThreadsPerBlock` to determine the register usage thresholds for the transitions between n and n+1 resident blocks (i.e., when using one less register makes room for an additional resident block as in the example of Multiprocessor Level) and then applies similar heuristics as when no launch bounds are specified;
    - If both `minBlocksPerMultiprocessor` and `maxThreadsPerBlock` are specified, the compiler may increase register usage as high as L to reduce the number of instructions and better hide single thread instruction latency.

A kernel will fail to launch if it is executed with more threads per block than its launch bound maxThreadsPerBlock.